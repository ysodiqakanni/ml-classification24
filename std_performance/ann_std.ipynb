{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aabc10e-446a-46c8-932c-f92c16d21278",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "33af2cdd-b6a0-48c2-8afb-9b42a557227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "d81d0688-68dd-47c0-8e8e-7c30abba8776",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_VAL = 0\n",
    "tf.__version__\n",
    "tf.random.set_seed(SEED_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "7dcfb14b-02ec-4601-9b09-7aee98e0f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset \n",
    "student_performance = fetch_ucirepo(id=320) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = student_performance.data.features.to_numpy()\n",
    "y_raw = student_performance.data.targets.to_numpy()\n",
    "#y_raw = y_raw[:, 2]  # I'm using only the 3rd target column (final grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b267e7ed-3094-404f-a9f4-84b312073b7b",
   "metadata": {},
   "source": [
    "### Converting y to a 1D array and Encode it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "935ac33a-ab3e-43bd-bbb2-7b63291d3354",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_raw[:, 2].ravel()\n",
    "#print(sorted(set(y)))\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "dee50da5-6028-4d4f-bada-95f9afbf29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEW! OneHotEncode y column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "9b496376-e770-4a32-b2fd-e8cc67fe0628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder(sparse_output=False)\n",
    "onehotencoder.fit(np.array([i for i in range(21)]).reshape(-1,1))\n",
    "# y_encoded = onehotencoder.fit_transform(y.reshape(-1, 1))\n",
    "# y_encoded.shape\n",
    "# y = y_encoded\n",
    "y_encoded = onehotencoder.transform(y.reshape(-1,1))\n",
    "y = y_encoded\n",
    "#print(yd[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2dd516-7963-4a1f-ab1e-fbec1543e4b2",
   "metadata": {},
   "source": [
    "## Encoding feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "56986832-fefe-4b13-bf12-692f109a9ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape before oneHot  (649, 30)\n",
      "new dim added:  (649, 5)\n",
      "X's shape after mjob5: (649, 34)\n",
      "new dim added:  (649, 5)\n",
      "X's shape after fjob5: (649, 38)\n",
      "new dim added:  (649, 4)\n",
      "X's shape after reason4: (649, 41)\n",
      "new guard cols added:  (649, 3)\n",
      "X's shape after guardian3: (649, 43)\n",
      "X's new shape: (649, 43)\n",
      "[0 0 18 1 0 0 4 4 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0\n",
      " 0.0 1.0 0.0 2 2 0 1 0 0 0 1 1 0 0 4 3 4 1 1 3 4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# encode the first column (school)\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "X[:, 1] = le.fit_transform(X[:, 1])   # gender\n",
    "\n",
    "# encode the 4th column. Rural or Urban\n",
    "X[:, 3] = le.fit_transform(X[:, 3])    # address type \n",
    "X[:, 4] = le.fit_transform(X[:, 4])    # family size\n",
    "X[:, 5] = le.fit_transform(X[:, 5])    # family cohabitation status\n",
    "\n",
    "print(\"X shape before oneHot \", X.shape)  # Todo: remove this\n",
    "\n",
    "# 9th column (mother's job) is nominal\n",
    "onehotencoder = OneHotEncoder(categories='auto', sparse_output=False)    # set to false to return ndarry instead of scipy.sparse._csr.csr_matrix\n",
    "col_9_encoded = onehotencoder.fit_transform(X[:, 8].reshape(-1, 1))\n",
    "print(\"new dim added: \", col_9_encoded.shape)\n",
    "X = np.concatenate((X[:,:8], col_9_encoded, X[:, 9:]), axis=1)  # add/concat the RHS array as a new column(s). Now we have 34cols\n",
    "# at this point, col9 at idx8 has extended to indexes 8,9,10,11,12 due to the new encoded indexes\n",
    "print(f\"X's shape after mjob5: {X.shape}\")\n",
    "\n",
    "# encoding father's job column. Originally col idx9, now idx13\n",
    "col_fjob_encoded = onehotencoder.fit_transform(X[:, 13].reshape(-1, 1))\n",
    "print(\"new dim added: \", col_fjob_encoded.shape)\n",
    "X = np.concatenate((X[:,:13], col_fjob_encoded, X[:, 14:]), axis=1)  # add/concat the RHS array as 5 new column(s)\n",
    "print(f\"X's shape after fjob5: {X.shape}\")\n",
    "\n",
    "# encoding the reason column\n",
    "col_reason_encoded = onehotencoder.fit_transform(X[:, 18].reshape(-1, 1))\n",
    "print(\"new dim added: \", col_reason_encoded.shape)\n",
    "X = np.concatenate((X[:,:18], col_reason_encoded, X[:, 19:]), axis=1)  # add/concat the RHS array as 4 new column(s)\n",
    "print(f\"X's shape after reason4: {X.shape}\")\n",
    "\n",
    "# encoding the guardian column\n",
    "col_guardian_encoded = onehotencoder.fit_transform(X[:, 22].reshape(-1, 1))\n",
    "print(\"new guard cols added: \", col_guardian_encoded.shape)\n",
    "X = np.concatenate((X[:,:22], col_guardian_encoded, X[:, 23:]), axis=1)  # add/concat the RHS array as 3 new column(s)\n",
    "print(f\"X's shape after guardian3: {X.shape}\")\n",
    "\n",
    "# encoding the remaining binary columns\n",
    "for col in range(28, 36):\n",
    "    X[:, col] = le.fit_transform(X[:, col]) \n",
    "\n",
    "print(f\"X's new shape: {X.shape}\")\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "4e627e84-f4f1-4261-93d5-96bde144c98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(649, 43)\n",
      "(649, 45)\n"
     ]
    }
   ],
   "source": [
    "# adding extra output columns to X\n",
    "G1,G2 = y_raw[:,0].reshape(-1,1), y_raw[:,1].reshape(-1,1)\n",
    "print(X.shape)\n",
    "X = np.concatenate((X, G1, G2), axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7942e23b-eea4-4e60-bce3-6da396309cf1",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "5194e800-16e6-451e-9ef4-1fa1a7b15c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8071de19-e8f0-47f4-abd8-1e35c8ff2b27",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "we scale the features so they're in the same range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "a7e87b32-4e32-4253-b85b-f7f37c9385fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08867c3a-8a58-4492-b05b-fb8b65e18395",
   "metadata": {},
   "source": [
    "## Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a6583d-8522-4b76-933c-d1da62da0510",
   "metadata": {},
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "a05e004e-69a1-401a-a2cd-6c0d6241cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b78590-6eb8-4cf7-b5f1-c30443fca6b5",
   "metadata": {},
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "7dd71534-6b94-49f7-91e4-236eb3dc0ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ann.add(tf.keras.layers.Dense(units=16, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44efb55-3b34-4c94-8d99-244b8e444567",
   "metadata": {},
   "source": [
    "### Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "e79ecfa2-423b-450b-9355-59cd0ea9fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ann.add(tf.keras.layers.Dense(units=8, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d60216-70cf-411f-86fa-f7fb567c8cdb",
   "metadata": {},
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "4bcca25d-2344-4c5b-93c9-62d1cfb3ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec8c14-1929-4149-b46f-77749b3ee835",
   "metadata": {},
   "source": [
    "## Training The ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3061e1-06e5-4c31-b1bf-4b1b91a570d8",
   "metadata": {},
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "b96c0bc8-2db4-4042-8355-3e06c477ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ann.fit(X_train, y_train, batch_size = 32, epochs = 100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "6c13f93d-890a-4ec7-a56c-4a9df4bdf3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836cf743-820a-4c33-9f5a-0e060ddad876",
   "metadata": {},
   "source": [
    "## Running GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "f7b50941-3e9a-40bd-858a-80c28474fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Running gridsearch...\")\n",
    "\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# # Function to create model, required for KerasClassifier\n",
    "# def create_modelOld(optimizer='adam', dropout_rate=0.0):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(64, input_dim=45, activation='relu'))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(17, activation='softmax'))\n",
    "#     model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# def create_model(optimizer='adam', init='uniform'):\n",
    "#     model = Sequential()\n",
    "#     # Input layer with 45 features\n",
    "#     model.add(Dense(64, input_dim=45, kernel_initializer=init, activation='relu'))\n",
    "#     model.add(Dense(64, kernel_initializer=init, activation='relu'))\n",
    "#     # Output layer with 21 classes and softmax activation\n",
    "#     model.add(Dense(21, kernel_initializer=init, activation='softmax'))\n",
    "    \n",
    "#     model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "#     return model\n",
    "    \n",
    "# #model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# # Define the grid of hyperparameters to search\n",
    "# param_grid = {\n",
    "#     'batch_size': [10, 20, 40],\n",
    "#     'epochs': [50, 100],\n",
    "#     'optimizer': ['adam', 'rmsprop'],\n",
    "#     'dropout_rate': [0.0, 0.2, 0.4]\n",
    "# }\n",
    "\n",
    "# print(\"Gridsearch done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814f667-6a24-4acf-9454-e037528ad2d4",
   "metadata": {},
   "source": [
    "## Building a custom ANN for multiclass problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "268e2350-5d47-4fb2-a6e9-3e2b785f74a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.0071 - loss: 5.0166 - val_accuracy: 0.0673 - val_loss: 4.7732\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1181 - loss: 4.7108 - val_accuracy: 0.1058 - val_loss: 4.5461\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1690 - loss: 4.4909 - val_accuracy: 0.1154 - val_loss: 4.3268\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1746 - loss: 4.2598 - val_accuracy: 0.0962 - val_loss: 4.0835\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1845 - loss: 4.0057 - val_accuracy: 0.1538 - val_loss: 3.8554\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1972 - loss: 3.7793 - val_accuracy: 0.1346 - val_loss: 3.6654\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2035 - loss: 3.5823 - val_accuracy: 0.1442 - val_loss: 3.5179\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2456 - loss: 3.4136 - val_accuracy: 0.1538 - val_loss: 3.3989\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2625 - loss: 3.2582 - val_accuracy: 0.1923 - val_loss: 3.2830\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2915 - loss: 3.1088 - val_accuracy: 0.1923 - val_loss: 3.1671\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3534 - loss: 2.9640 - val_accuracy: 0.2212 - val_loss: 3.0493\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4191 - loss: 2.8271 - val_accuracy: 0.2500 - val_loss: 2.9337\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4398 - loss: 2.6996 - val_accuracy: 0.2596 - val_loss: 2.8379\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4814 - loss: 2.5806 - val_accuracy: 0.2692 - val_loss: 2.7567\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4842 - loss: 2.4721 - val_accuracy: 0.2788 - val_loss: 2.6930\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5046 - loss: 2.3738 - val_accuracy: 0.2692 - val_loss: 2.6427\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5241 - loss: 2.2819 - val_accuracy: 0.2596 - val_loss: 2.6022\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5406 - loss: 2.1997 - val_accuracy: 0.2788 - val_loss: 2.5746\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5505 - loss: 2.1241 - val_accuracy: 0.2596 - val_loss: 2.5606\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5819 - loss: 2.0539 - val_accuracy: 0.2500 - val_loss: 2.5530\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6187 - loss: 1.9882 - val_accuracy: 0.2596 - val_loss: 2.5492\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6396 - loss: 1.9287 - val_accuracy: 0.2596 - val_loss: 2.5519\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6811 - loss: 1.8756 - val_accuracy: 0.2692 - val_loss: 2.5597\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6990 - loss: 1.8233 - val_accuracy: 0.2596 - val_loss: 2.5711\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7230 - loss: 1.7726 - val_accuracy: 0.2500 - val_loss: 2.5866\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7420 - loss: 1.7268 - val_accuracy: 0.2596 - val_loss: 2.5999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20f4a365610>"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "# Build the ANN model\n",
    "input_dim = 45\n",
    "output_dim = 21\n",
    "# model = Sequential([\n",
    "#     Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(output_dim, activation='softmax')  # 21 neurons for 21 classes\n",
    "# ])\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# model = Sequential([\n",
    "#     Dense(64, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.01)),\n",
    "#     Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "#     Dense(output_dim, activation='softmax')\n",
    "# ])\n",
    "\n",
    "\n",
    "\n",
    "# model = Sequential([\n",
    "#     Dense(64, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.01)),\n",
    "#     Dropout(0.2),  # Add dropout after first layer (50% neurons dropped)\n",
    "#     Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "#     Dropout(0.2),  # Add dropout after second layer\n",
    "#     Dense(output_dim, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# more hidden layers\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.01)),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),  # Added hidden layer\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),  # Added another hidden layer\n",
    "    Dense(output_dim, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "fbe8f632-ca30-456f-a993-260f5d8734bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6137 - loss: 1.9415 \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2718 - loss: 2.5804 \n",
      "Test Accuracy: 0.58\n",
      "Test Accuracy: 0.32\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss_train, accuracy_train = model.evaluate(X_train, y_train)\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy_train:.2f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ade830-8cd3-4447-95b7-c55047defcb9",
   "metadata": {},
   "source": [
    "### Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9e3b19-e8b3-4098-b087-61449219b054",
   "metadata": {},
   "source": [
    "## Model Predictions and Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d4646a-a19b-4a93-985a-1a0101ae5f98",
   "metadata": {},
   "source": [
    "### Predicting Insample test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "5f51ccd0-7361-4c80-9075-4ca115958f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_ins = ann.predict(X_train)\n",
    "# y_pred_ins = (y_pred_ins > 0.5).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "9f2ca62f-70d4-4e20-907f-f6615ba8c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Getting the accuracy score\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "# cm = confusion_matrix(y_train, y_pred_ins)\n",
    "# #print(cm)\n",
    "# accuracy_score(y_train, y_pred_ins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df31d70-b156-49b9-beaf-6fd99044fdb6",
   "metadata": {},
   "source": [
    "### Out-Sample Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "637c7ed3-5686-4981-a9ad-50b1d7bf0e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = ann.predict(X_test)\n",
    "# y_pred = (y_pred > 0.5).astype(\"int\")\n",
    "# #print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "2ec873b8-d747-4384-95b7-f59c1e860975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# #print(cm)\n",
    "# accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322defe6-c9ab-4d6b-8ab0-069b1b698ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ac867-f8fe-481f-bbf3-22dcd61eb605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f529ad-4de7-46ae-bbed-6c960ea84969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
